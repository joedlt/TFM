{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Del fichero extraido con todoas las operciones por minutos de las tarjetas, se debe filtrar por los comercios\n",
    "#de los sectores y dentro de los codigos postales escogidos para el TFM .\n",
    "\n",
    "# Son alrededor de 60 millones de registros por tal motivo y como son datos sensibles del banco y de protecion de\n",
    "#medios de pago no se puede realizar el filtrado en un cluster asi que se buscan otros procedimientos en local\n",
    "#se miro la libreria dask que trabaja en disco y no en memoria, pero para recuperar el csv graba ficheros particionados\n",
    "# se decide ingresarlo en un base de Datos en postgresql, mediante la libreria odo que utiliza por debajo sqlalchemy\n",
    "#que igualmente toca instalar. Se utiliza odo porque mejora el proceso de conversion de dataframe a Base de datos \n",
    "#reduciendo el tiempo de ejecuci칩n.\n",
    "#La encriptacion de los numeros de tarjeta se ha puesto XXXXXXX por que estos datos seran privados y ocultos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\Miniconda3\\lib\\site-packages\\odo\\backends\\pandas.py:94: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access NaTType as type(pandas.NaT)\n",
      "  @convert.register((pd.Timestamp, pd.Timedelta), (pd.tslib.NaTType, type(None)))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from odo import odo,chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comercios=pd.read_csv('C:/Users/Jose/Documents/Master Data Science/TFM/Comercios_Tarjetas_TFM.txt',delimiter=';',quotechar='\"',dtype={'Cod_comercio':str,'Cod_postal':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sectores_TFM=pd.read_csv('C:/Users/Jose/Documents/Master Data Science/TFM/Sectores_TFM.txt',delimiter=';',quotechar='|',encoding='latin1',dtype={'Cod_sector':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Num 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:11: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "C:\\Users\\Jose\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "C:\\Users\\Jose\\Miniconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Num 1\n",
      "Chunk Num 2\n",
      "Chunk Num 3\n",
      "Chunk Num 4\n",
      "Chunk Num 5\n",
      "Chunk Num 6\n",
      "Chunk Num 7\n",
      "Chunk Num 8\n",
      "Chunk Num 9\n",
      "Chunk Num 10\n",
      "Chunk Num 11\n",
      "Chunk Num 12\n",
      "Chunk Num 13\n",
      "Chunk Num 14\n",
      "Chunk Num 15\n",
      "Chunk Num 16\n",
      "Chunk Num 17\n",
      "Chunk Num 18\n",
      "Chunk Num 19\n",
      "Chunk Num 20\n",
      "Chunk Num 21\n",
      "Chunk Num 22\n",
      "Chunk Num 23\n",
      "Chunk Num 24\n",
      "Chunk Num 25\n",
      "Chunk Num 26\n",
      "Chunk Num 27\n",
      "Chunk Num 28\n",
      "Chunk Num 29\n",
      "Chunk Num 30\n",
      "Chunk Num 31\n",
      "Chunk Num 32\n",
      "Chunk Num 33\n",
      "Chunk Num 34\n",
      "Chunk Num 35\n",
      "Chunk Num 36\n",
      "Chunk Num 37\n",
      "Chunk Num 38\n",
      "Chunk Num 39\n",
      "Chunk Num 40\n",
      "Chunk Num 41\n",
      "Chunk Num 42\n",
      "Chunk Num 43\n",
      "Chunk Num 44\n",
      "Chunk Num 45\n",
      "Chunk Num 46\n",
      "Chunk Num 47\n",
      "Chunk Num 48\n",
      "Chunk Num 49\n",
      "Chunk Num 50\n",
      "Chunk Num 51\n",
      "Chunk Num 52\n",
      "Chunk Num 53\n",
      "Chunk Num 54\n",
      "Chunk Num 55\n",
      "Chunk Num 56\n",
      "Chunk Num 57\n",
      "Chunk Num 58\n",
      "Chunk Num 59\n",
      "Wall time: 3h 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pp= pd.read_csv('C:/Users/Jose/Documents/Master Data Science/TFM/Tarjetas.txt',sep=';',decimal=',',quotechar='\"', usecols=[0,1,2,4,5,6,10],\n",
    "                names=[\"Fecha\",\"Horas\",\"Tarjeta\",\"Cod_persona\", \"Cod_sector\",\"Cod_comercio\",\"Importe\"]\\\n",
    "                ,dtype={'Fecha':str,'Horas':str,'Tarjeta':str,'Cod_comercio':str,'Cod_sector':str,'Cod_persona':str},chunksize=1000000)\n",
    "\n",
    "all_chunk_results=pd.DataFrame()\n",
    "for (i, chunk) in enumerate(pp):\n",
    "    print(\"Chunk Num %d\"%i)\n",
    "    \n",
    "    chunk.Fecha=chunk.Fecha.str.replace('^(\\ufeff)','')\n",
    "    b=chunk.Horas\n",
    "    h=b.str.extract('^(\\d{2})')\n",
    "    ms=b.str.extract('(\\d{4})$')\n",
    "    m=ms.str.extract('^(\\d{2})')\n",
    "    s='00'\n",
    "    time=h+\":\"+m+\":\"+s+\".\"+\"000\"\n",
    "    Date=chunk.Fecha+\" \"+time\n",
    "    Date=pd.to_datetime(Date, format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    Date_hour=pd.to_datetime(Date.dt.date) + pd.to_timedelta(Date.dt.hour, unit='H')\n",
    "    Hora=pd.to_datetime(Date_hour,format=\"%H:%M\").dt.time\n",
    "    Dia=Date_hour.dt.date\n",
    "    Dia_semana=Date_hour.dt.dayofweek\n",
    "    days={0:'Lun',1:'Mar',2:'Mie',3:'Jue',4:'Vie',5:'Sab',6:'Dom'}\n",
    "    Dia_semana=Dia_semana.apply(lambda x:days[x])\n",
    "    Mes=Date.apply(lambda x: x.month)\n",
    "    month={1:'Ene',2:'Feb',3:'Mar',4:'Abr',5:'May',6:'Jun',7:'Jul',8:'Ago',9:'Sep',10:'Oct',11:'Nov',12:'Dic'}\n",
    "    Mes=Mes.apply(lambda x:month[x])\n",
    "    A침o=Date.dt.year\n",
    "    char=\"0123456789\"\n",
    "    encrip=\"XXXXXXXXXX\"\n",
    "    trans = str.maketrans(char, encrip)\n",
    "    t=chunk.Tarjeta\n",
    "    t1=t.str.translate(trans)\n",
    "    chunk['Hora']=Hora\n",
    "    chunk['Dia']=Dia\n",
    "    chunk['Dia_semana']=Dia_semana\n",
    "    chunk['Mes']=Mes\n",
    "    chunk['A침o']=A침o\n",
    "    chunk['Cod_tarjeta']=t1\n",
    "    chunk['Cod_tarjeta']=chunk.Cod_tarjeta.str.strip()\n",
    "    chunk['Cod_comercio']=chunk.Cod_comercio.str.strip()\n",
    "    chunk.drop('Fecha', axis=1, inplace=True)\n",
    "    chunk.drop('Horas', axis=1, inplace=True)\n",
    "    chunk.drop('Tarjeta', axis=1, inplace=True)\n",
    "    chunk_result=pd.merge(chunk,sectores_TFM, on='Cod_sector',how='inner')\n",
    "    chunk_result1=pd.merge(chunk_result,comercios, on='Cod_comercio',how='inner')\n",
    "    odo(chunk_result1,'postgresql://postgres:jose@localhost:5432/TFM::Ope_tarjetas',if_exists='append')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
